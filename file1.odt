ASSIGNMENT-2 MARKOV DECISION PROCESS

-TEAM 82
-201501115

PART1

Iteration: 1

 y  y  82.00  y

 -4.10  -4.10  61.50  -4.10

 -4.10  -82.00  y  -4.10

 -4.10  -4.10  -4.10  -4.10


Iteration: 2

 y  y  82.00  y

 -8.20  36.49  60.68  44.28

 -8.20  -82.00  y  -8.20

 -8.20  -8.20  -8.20  -8.20


Iteration: 3

 y  y  82.00  y

 23.45  39.89  69.58  48.05

 -12.30  -82.00  y  29.68

 -12.30  -12.30  -12.30  -12.30


Iteration: 4

 y  y  82.00  y

 28.93  47.35  70.29  59.34

 5.23  -82.00  y  40.28

 -16.40  -16.40  -16.40  17.19


Iteration: 5

 y  y  82.00  y

 37.20  48.67  72.17  62.10

 11.37  -82.00  y  51.42

 -3.19  -20.50  6.37  28.20


Iteration: 6

 y  y  82.00  y

 39.69  50.30  72.58  64.99

 18.59  -82.00  y  55.86

 2.62  -9.25  19.74  40.50


Iteration: 7

 y  y  82.00  y

 41.97  50.79  73.03  66.05

 21.31  -82.00  y  59.06

 10.11  2.56  32.24  46.61


Iteration: 8

 y  y  82.00  y

 42.86  51.20  73.18  66.83

 23.41  -82.00  y  60.55

 14.22  13.75  39.64  51.04


Iteration: 9

 y  y  82.00  y

 43.49  51.37  73.30  67.19

 24.33  -82.00  y  61.48

 17.42  20.79  44.66  53.41


Iteration: 10

 y  y  82.00  y

 43.78  51.48  73.36  67.41

 24.92  -82.00  y  61.94

 19.19  25.50  47.56  54.89


Iteration: 11

 y  y  82.00  y

 43.95  51.53  73.39  67.52

 25.21  -82.00  y  62.22

 20.71  28.30  49.32  55.70
Number of Iterations: 11


PART2

Final Expected Utility:

y	y           82.00	 y

43.95 	51.53 	73.39	67.52

25.21   -82.00      y        62.22

20.71   28.30     49.32    55.70


Optimal Policy for each state:

y	y	T	y

E	E	S	W

S	T	y	S

E	E	E	S

Optimal Path:

(3,0) -> (3,1) -> (3,2) -> (3,3) -> (2,3) -> (1,3) -> (1,2) -> (0,2)



PART 3:
